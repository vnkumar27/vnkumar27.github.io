---
layout: post
title: Is that spot open?  

---


We are more than 50% done with the bootcamp! Here are some details on our third project for Metis.  


## Project McNulty 

Instructions: Classify something. Anything. And then create a web app that includes a D3 visualization to showcase your final product.  

### Project Idea 

Our group decided to classify parking spots in a business parking lot to determine how full the lot was at a given time.  

### Data:
 
We found a dataset of over 12,000 images taken from a parking lot camera for a business parking lot. The images are all from the same angle and of the same parking lot and were taken at multiple times over every hour of the day.  

### Details: 

There were several layers to our classification. First, we needed to analyze images and make an algorithm that would identify parking spots. Then, we needed to find a method to determine whether or not the spot was occupied.  

It turns out that it is not very easy to accurately pick out the white parking lines in an image! Since we were pressed for time and faced trouble with extracting the locations of the white parking lines, we decided to manually assign the centroid points to every spot on one image. Since all of the images were taken in the same position, it was easy to apply those centroid coordinates to the other images.  

Next, we ran SIFT (Scale Invariant Feature Transform) to populate the image with "density points". We adjusted the radius and edge identification parameters of the SIFT analysis so that it would place points on the vehicles, if there was one. Since the images were taken during various weather conditions, the image saturation was not consistent and therefore the successful placement of SIFT points varied across weather differences. Therefore we decided to first test our algorithm on one weather condition, which in this case was "cloudy".  

Once we placed the SIFT points we ran both KD-Tree and Ball Tree to count the SIFT point density around the centroids. We classified the spot as "full" if there were 4 or more SIFT points. The following scores show how our model performed:  

Accuracy Score: 95.3%  
Recall Score: 93.4%  
Precision Score: 72.2%  

The final step was to create a webapp and D3 visualization. We created two visualizations for our final app, as seen in the below screenshot of our web Flask app. The first visual is a heatmap that depicts how the parking lot capacity varied over 6am to 6pm from Monday through Friday. The second visual shows one of the images from our dataset and, with a click of a button, is populated with red or green dots to indicate how our algorithm classified spots as full or not full, respectively.  


![McNulty Image]({{site.baseurl}}/images/mcnulty_1.png)

### Analysis: 

Overall I think we did a great job given the limited time and expertise in this specific classification problem. In addition to exercising classification algorithms, we also had to learn about image composition in order vary the colors in the image to best satisfy our SIFT analysis. Although we had an average over prediction rate of 19.7%, we still were able to identify taken spots with a high accuracy.  

### For next time:  

We would need to do some more tinkering with color scales and object identification so that we can extract the parking spot centroids without any manual intervention. This would allow us to extrapolate our algorithms to different parking lots. This business case for this application is enormous, and with enough resources and time we could apply this algorithm to parking garages in a city and connect it with a mobile app that would tell you parking availability in real-time. For those of us living in crowded cities, that knowledge is very valuable!  